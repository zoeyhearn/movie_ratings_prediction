{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_table(\"title.basics.tsv.gz\",compression='gzip',sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_table(\"title.ratings.tsv.gz\",compression='gzip',sep='\\t', low_memory=False)\n",
    "df_basics = pd.read_table(\"title.basics.tsv.gz\",compression='gzip',sep='\\t', low_memory=False)\n",
    "df_akas = pd.read_table(\"title.akas.tsv.gz\",compression='gzip',sep='\\t', low_memory=False)\n",
    "df_crew = pd.read_table(\"title.crew.tsv.gz\",compression='gzip',sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times the movie has been translated\n",
    "df_translations = df_akas.groupby(['titleId']).size().reset_index(name='counts')\n",
    "df_translations.columns = ['tconst', 'numTranslations']\n",
    "\n",
    "# Join data frames together\n",
    "df_joined = df_ratings.join(df_basics.set_index('tconst'),on='tconst').join(\n",
    "            df_translations.set_index('tconst'),on='tconst').join(\n",
    "            df_crew.set_index('tconst'),on='tconst')\n",
    "\n",
    "# Drop rows where there is missing information\n",
    "df_complete_data = df_joined[df_joined['titleType'].str.contains(\"movie\")]\n",
    "df_clean_up = df_complete_data[df_complete_data.runtimeMinutes.str.contains(\"\\N\") == False]\n",
    "df_clean_up = df_clean_up[df_clean_up.directors.str.contains(\"\\N\") == False]\n",
    "df_clean_up = df_clean_up[df_clean_up.writers.str.contains(\"\\N\") == False]\n",
    "\n",
    "# Drop columns that don't hold any information\n",
    "df_clean = df_clean_up.drop(['titleType', 'primaryTitle', 'directors',\n",
    "                             'writers', 'originalTitle', 'endYear',\n",
    "                             'isAdult', 'tconst'], axis=1)\n",
    "\n",
    "# Count number times the director and writer have directed/written movies in dataset\n",
    "directorPopularity = df_clean_up['directors'].value_counts().to_dict()\n",
    "df_clean['directorPopularity'] = df_clean_up['directors'].map(directorPopularity)\n",
    "writerPopularity = df_clean_up['writers'].value_counts().to_dict()\n",
    "df_clean['writerPopularity'] = df_clean_up['writers'].map(writerPopularity)\n",
    "\n",
    "# One hot encoding for movie genres\n",
    "genre_dummies = df_clean['genres'].str.get_dummies(sep=',')\n",
    "df_one_hot_encoding = df_clean.join(genre_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final clean up, drop irrelevant information, fill NaN values with 0\n",
    "# Make sure all data is in correct numerical format\n",
    "data = df_one_hot_encoding.drop(['genres'], axis = 1).fillna(0).reset_index(\n",
    "                                drop=True).apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "# Split data into features and target value (movie rating)\n",
    "X = data.drop('averageRating', axis = 1)\n",
    "y = data['averageRating']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=11, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor(max_depth = 11)  \n",
    "tree.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average distance from correct rating:', 0.8485096668466539)\n"
     ]
    }
   ],
   "source": [
    "def loss(y_test, y_predict):\n",
    "    return np.sum(abs(y_test-y_predict))/len(y_test)\n",
    "\n",
    "print ('Average distance from correct rating:', loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization for tree of depth 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pydotplus",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bb2346ea1a0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvisualization_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pydotplus"
     ]
    }
   ],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "visualization_tree = DecisionTreeRegressor(max_depth = 3)\n",
    "visualization_tree.fit(X_train, y_train) \n",
    "dot_data = StringIO()\n",
    "export_graphviz(visualization_tree, out_file=dot_data,\n",
    "                feature_names = X.columns.values)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train a random forrest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forrest = RandomForestRegressor(max_depth=20, random_state=0, n_estimators=50)\n",
    "forrest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test random forrest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average distance from correct rating:', 0.8125570503971087)\n"
     ]
    }
   ],
   "source": [
    "y_pred_forrest = forrest.predict(X_test)\n",
    "print ('Average distance from correct rating:', loss(y_pred_forrest, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
